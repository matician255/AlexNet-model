import tensorflow as tf
from tensorflow.keras import layers, models, optimizers, regularizers
from tensorflow.keras.datasets import IMAGENET
from tensorflow.keras.utils import to_categorical

# Load and preprocess the IMAGENET dataset
def load_and_preprocess_data():
    (x_train, y_train), (x_test, y_test) = IMAGENET.load_data()

    # Normalize pixel values to [0, 1]
    x_train = x_train.astype('float32') / 255.0
    x_test = x_test.astype('float32') / 255.0

    # One-hot encode labels
    y_train = to_categorical(y_train, 10)
    y_test = to_categorical(y_test, 10)

    return x_train, y_train, x_test, y_test

# Define the AlexNet model
def build_alexnet(input_shape=(227, 227, 3), num_classes=10):
    model = models.Sequential([
        # Layer 1: Convolutional + ReLU + MaxPooling
        layers.Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=input_shape),
        layers.BatchNormalization(),
        layers.MaxPooling2D((3, 3), strides=(2, 2)),

        # Layer 2: Convolutional + ReLU + MaxPooling
        layers.Conv2D(256, (5, 5), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((3, 3), strides=(2, 2)),

        # Layer 3: Convolutional + ReLU
        layers.Conv2D(384, (3, 3), padding='same', activation='relu'),

        # Layer 4: Convolutional + ReLU
        layers.Conv2D(384, (3, 3), padding='same', activation='relu'),

        # Layer 5: Convolutional + ReLU + MaxPooling
        layers.Conv2D(256, (3, 3), padding='same', activation='relu'),
        layers.MaxPooling2D((3, 3), strides=(2, 2)),

        # Flatten the output for fully connected layers
        layers.Flatten(),

        # Layer 6: Fully Connected + ReLU + Dropout
        layers.Dense(4096, activation='relu'),
        layers.Dropout(0.5),

        # Layer 7: Fully Connected + ReLU + Dropout
        layers.Dense(4096, activation='relu'),
        layers.Dropout(0.5),

        # Output Layer: Fully Connected + Softmax
        layers.Dense(num_classes, activation='softmax')
    ])

    return model

# Compile the model
def compile_model(model):
    model.compile(
        optimizer=optimizers.Adam(learning_rate=0.001),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

# Train the model
def train_model(model, x_train, y_train, x_test, y_test, epochs=10, batch_size=128):
    history = model.fit(
        x_train, y_train,
        validation_data=(x_test, y_test),
        epochs=epochs,
        batch_size=batch_size,
        verbose=1
    )
    return history

# Main function to run the AlexNet pipeline
def main():
    # Load and preprocess data
    x_train, y_train, x_test, y_test = load_and_preprocess_data()

    # Build the AlexNet model
    model = build_alexnet()
    model = compile_model(model)

    # Print model summary
    model.summary()

    # Train the model
    history = train_model(model, x_train, y_train, x_test, y_test, epochs=10, batch_size=128)

    # Evaluate the model
    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
    print(f"\nTest Accuracy: {test_acc:.4f}")
